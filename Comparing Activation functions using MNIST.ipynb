{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be fitting a neural network to the MNIST data set using Tensor Flow. The various network structures, activation functions, optimization methods, and/or hyperparameter settings will be tested. Classification performance accuracy and processing time will be assessed using the Benchmark Experiment design. Only the train and test dataset and 2x2 design (experiments) will be used for the experiment.\n",
    "\n",
    "The model having greatest Train and Test set Accuracy is 5-Layer NN having 20 nodes and ELU activation function.\n",
    "The model having lease Runtime is 2-Layer NN having 10 nodes and Tanh activation function.\n",
    "\n",
    "The models having average Train and Test set Accuracy and Runtime are:\n",
    "\n",
    "1. 5-Layer NN having 20 nodes and Tanh activation function\n",
    "2. 5-Layer NN having 10 nodes and ELU activation function\n",
    "3. 2-Layer NN having 20 nodes and Tanh activation function\n",
    "4. 2-Layer NN having 10 nodes and ELU activation function\n",
    "\n",
    "If performance is a priority then I will recommend using 5-Layer NN having 20 nodes and ELU activation function as it has better Train and Test Accuracy. However, the 2-Layer NN having 20 nodes and Tanh activation function has a good Accuracy and Runtime tradeoff. So if timing needs to be considered as well then this Model can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Train and Test files for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure common functions across Python 2 and 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# import base packages into the namespace for this program\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from astropy.table import Table\n",
    "#from tabulate import tabulate\n",
    "\n",
    "# Use to build neural network\n",
    "import tensorflow as tf\n",
    "\n",
    "# Stores MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# To remove warnings from code\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "WORK_DIRECTORY = \"./mnist-data\"\n",
    "\n",
    "import gzip, binascii, struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded train-images-idx3-ubyte.gz\n",
      "Already downloaded train-labels-idx1-ubyte.gz\n",
      "Already downloaded t10k-images-idx3-ubyte.gz\n",
      "Already downloaded t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping the Train and Test files to extract the Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist-data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist-data\\t10k-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "PIXEL_DEPTH = 255\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  \n",
    "    For MNIST data, the number of channels is always 1.\n",
    "\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and dimensions; we know these values.\n",
    "        bytestream.read(16)\n",
    "\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "        return data\n",
    "\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 10\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and count; we know these values.\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return (np.arange(NUM_LABELS) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train object: <class 'numpy.ndarray'> (60000, 784)\n",
      "\n",
      "y_train object: <class 'numpy.ndarray'> (60000,)\n",
      "\n",
      "X_test object: <class 'numpy.ndarray'> (10000, 784)\n",
      "\n",
      "y_test object: <class 'numpy.ndarray'> (10000,)\n"
     ]
    }
   ],
   "source": [
    "# user-defined function to convert binary digits to digits 0-9\n",
    "def label_transform(y_in):\n",
    "    for i in range(len(y_in)):\n",
    "        if (y_in[i] == 1): return i\n",
    "\n",
    "y_train = []    \n",
    "for j in range(train_labels.shape[0]):\n",
    "    y_train.append(label_transform(train_labels[j,]))  \n",
    "y_train = np.asarray(y_train)    \n",
    "\n",
    "y_test = []    \n",
    "for j in range(test_labels.shape[0]):\n",
    "    y_test.append(label_transform(test_labels[j,]))  \n",
    "y_test = np.asarray(y_test)    \n",
    "    \n",
    "# 28x28 matrix of entries converted to vector of 784 entries    \n",
    "X_train = train_data.reshape(60000, 784)\n",
    "X_test = test_data.reshape(10000, 784)\n",
    "\n",
    "# check data intended for Scikit Learn input\n",
    "print('\\nX_train object:', type(X_train), X_train.shape)    \n",
    "print('\\ny_train object:', type(y_train),  y_train.shape)  \n",
    "print('\\nX_test object:', type(X_test),  X_test.shape)  \n",
    "print('\\ny_test object:', type(y_test),  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 28*28  # MNIST dataset features\n",
    "N_OUTPUTS = 10    # Categories (number of digits)\n",
    "  \n",
    "tf.set_random_seed(111)\n",
    "\n",
    "# optimizer to minimize the cost function\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset graph to make output stable across runs\n",
    "def reset_graph(seed=111):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_NN(n_hidden1, n_hidden2, activate):\n",
    "    \n",
    "    # reset graph\n",
    "    reset_graph()\n",
    "    \n",
    "    tf.set_random_seed(111)\n",
    "    # setup placeholder nodes to represent the training data and targets\n",
    "    X = tf.placeholder(tf.float32, shape=(None, N_INPUTS), name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\") \n",
    "    \n",
    "    # Create Neural Network\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                                activation=activate)\n",
    "        hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                                activation=activate)\n",
    "        logits = tf.layers.dense(hidden2, N_OUTPUTS, name=\"outputs\") \n",
    "    \n",
    "    # Cost function used to train Neural Network\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                                logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "        \n",
    "    # Measure classification performance\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))  \n",
    "    \n",
    "    # Node to initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Create saver object to save traned model parameters to disk\n",
    "    saver = tf.train.Saver(save_relative_paths=True) \n",
    "\n",
    "    # Execute Model \n",
    "    \n",
    "    # Train model \n",
    "    n_epochs = 20\n",
    "    batch_size = 50\n",
    "    \n",
    "    # Start clock to time training time for NN\n",
    "    start_time = time.clock()\n",
    "    \n",
    "    # The next_batch function is doing random sampling \n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            rnd_idx = np.random.permutation(len(X_train))\n",
    "            n_batches = X_train.shape[0] // batch_size\n",
    "            for iteration in np.array_split(rnd_idx, n_batches):\n",
    "                X_batch, y_batch = X_train[iteration], y_train[iteration]\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "    \n",
    "        save_path = saver.save(sess, './model_2_final.ckpt')\n",
    "    \n",
    "    # restoring graph parameters and run against holdout data      \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, save_path)\n",
    "        accuracy = accuracy.eval(feed_dict={X: X_test, \n",
    "                                        y: y_test})\n",
    "    \n",
    "    # Start clock to time training time for NN\n",
    "    stop_time = time.clock()\n",
    "    \n",
    "    #Total Time\n",
    "    runtime = stop_time - start_time \n",
    "    return n_hidden1, n_hidden2, str(activate), acc_train, runtime, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Five Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_layer_NN(n_hidden1, n_hidden2, n_hidden3, n_hidden4,\n",
    "                    n_hidden5, activate):\n",
    "    \n",
    "    # reset graph\n",
    "    reset_graph()\n",
    "    \n",
    "    tf.set_random_seed(111)\n",
    "    \n",
    "    # setup placeholder nodes to represent the training data and targets\n",
    "    X = tf.placeholder(tf.float32, shape=(None, N_INPUTS), name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\") \n",
    "    \n",
    "    # Create Neural Network\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                                activation=activate)\n",
    "        hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                                activation=activate)\n",
    "        hidden3 = tf.layers.dense(hidden2, n_hidden3, name=\"hidden3\",\n",
    "                                activation=activate)\n",
    "        hidden4 = tf.layers.dense(hidden3, n_hidden4, name=\"hidden4\",\n",
    "                                activation=activate)\n",
    "        hidden5 = tf.layers.dense(hidden4, n_hidden5, name=\"hidden5\",\n",
    "                                activation=activate)\n",
    "        logits = tf.layers.dense(hidden5, N_OUTPUTS, name=\"outputs\") \n",
    "    \n",
    "    # Cost function used to train Neural Network\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                                logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "        \n",
    "    # Measure classification performance\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))  \n",
    "    \n",
    "    # Node to initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Create saver object to save traned model parameters to disk\n",
    "    saver = tf.train.Saver(save_relative_paths=True) \n",
    "\n",
    "    # Execute Model \n",
    "    \n",
    "    # Train model \n",
    "    n_epochs = 20\n",
    "    batch_size = 50\n",
    "    \n",
    "    # Start clock to time training time for NN\n",
    "    start_time = time.clock()\n",
    "    \n",
    "    # The next_batch function is essentially doing random sampling so the results\n",
    "    # won't be consistent from run to run\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            rnd_idx = np.random.permutation(len(X_train))\n",
    "            n_batches = X_train.shape[0] // batch_size\n",
    "            for iteration in np.array_split(rnd_idx, n_batches):\n",
    "                X_batch, y_batch = X_train[iteration], y_train[iteration]\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "    \n",
    "        save_path = saver.save(sess, './model_5_final.ckpt')\n",
    "    \n",
    "    # Now restore graph parameters and run against holdout data for final score      \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, save_path)\n",
    "        accuracy = accuracy.eval(feed_dict={X: X_test, \n",
    "                                        y: y_test})\n",
    "    \n",
    "    # Start clock to time training time for NN\n",
    "    stop_time = time.clock()\n",
    "    \n",
    "    #Total Time\n",
    "    runtime = stop_time - start_time  \n",
    "    \n",
    "    return n_hidden1, n_hidden2, n_hidden3, n_hidden4, n_hidden5,\\\n",
    "                str(activate), acc_train, runtime, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different node configerations were passed to the function with \n",
    "# different activation functions\n",
    "nn_layer_2 = [[10,10, tf.nn.relu], [20,20, tf.nn.relu],\n",
    "              [10,10, tf.nn.tanh], [20,20, tf.nn.tanh], \n",
    "              [10,10, tf.nn.elu], [20,20, tf.nn.elu]]\n",
    "\n",
    "exp_result_2 = []\n",
    "for m in nn_layer_2 :\n",
    "    exp_result_2.append(two_layer_NN(m[0],m[1], m[2]))\n",
    "    \n",
    "names=['hidden1','hidden2', 'activation',\n",
    "        'Train Accuracy','Runtime','Test Accuracy']\n",
    "result_df_2 = pd.DataFrame(exp_result_2)\n",
    "result_df_2.columns=names\n",
    "result_df_2['layers']= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with 5-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different node configerations were passed to the function with \n",
    "#different activation functions\n",
    "nn_layer_5 = [[10,10,10,10,10,tf.nn.relu], [20,20,20,20,20,tf.nn.relu],\n",
    "              [10,10,10,10,10,tf.nn.tanh], [20,20,20,20,20,tf.nn.tanh], \n",
    "              [10,10,10,10,10,tf.nn.elu], [20,20,20,20,20,tf.nn.elu]]\n",
    "\n",
    "exp_result_5 = []\n",
    "for m in nn_layer_5 :\n",
    "    exp_result_5.append(five_layer_NN(m[0],m[1], m[2], m[3], m[4], m[5]))\n",
    "\n",
    "names5=['hidden1','hidden2','hidden3','hidden4', 'hidden5', 'activation',\n",
    "        'Train Accuracy','Runtime','Test Accuracy']\n",
    "result_df_5 = pd.DataFrame(exp_result_5)\n",
    "result_df_5.columns=names5\n",
    "result_df_5['layers']= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-Layer NN Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden1</th>\n",
       "      <th>hidden2</th>\n",
       "      <th>activation</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;function elu at 0x0000017F5C2A0048&gt;</td>\n",
       "      <td>0.92</td>\n",
       "      <td>15.994504</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;function relu at 0x0000017F5C2AF598&gt;</td>\n",
       "      <td>0.92</td>\n",
       "      <td>15.860860</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;function tanh at 0x0000017F5C1350D0&gt;</td>\n",
       "      <td>0.98</td>\n",
       "      <td>15.870896</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function elu at 0x0000017F5C2A0048&gt;</td>\n",
       "      <td>0.94</td>\n",
       "      <td>14.503777</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function relu at 0x0000017F5C2AF598&gt;</td>\n",
       "      <td>0.94</td>\n",
       "      <td>15.677235</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function tanh at 0x0000017F5C1350D0&gt;</td>\n",
       "      <td>0.92</td>\n",
       "      <td>14.536947</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden1  hidden2                             activation  Train Accuracy  \\\n",
       "5       20       20   <function elu at 0x0000017F5C2A0048>            0.92   \n",
       "1       20       20  <function relu at 0x0000017F5C2AF598>            0.92   \n",
       "3       20       20  <function tanh at 0x0000017F5C1350D0>            0.98   \n",
       "4       10       10   <function elu at 0x0000017F5C2A0048>            0.94   \n",
       "0       10       10  <function relu at 0x0000017F5C2AF598>            0.94   \n",
       "2       10       10  <function tanh at 0x0000017F5C1350D0>            0.92   \n",
       "\n",
       "     Runtime  Test Accuracy  layers  \n",
       "5  15.994504         0.9466       2  \n",
       "1  15.860860         0.9459       2  \n",
       "3  15.870896         0.9442       2  \n",
       "4  14.503777         0.9320       2  \n",
       "0  15.677235         0.9255       2  \n",
       "2  14.536947         0.9237       2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordered based on accuracy and runtime\n",
    "result_df_2.sort_values(['Test Accuracy', 'Runtime'], ascending=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-Layer NN Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden1</th>\n",
       "      <th>hidden2</th>\n",
       "      <th>hidden3</th>\n",
       "      <th>hidden4</th>\n",
       "      <th>hidden5</th>\n",
       "      <th>activation</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;function elu at 0x0000017F5C2A0048&gt;</td>\n",
       "      <td>0.98</td>\n",
       "      <td>19.796811</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;function relu at 0x0000017F5C2AF598&gt;</td>\n",
       "      <td>0.96</td>\n",
       "      <td>18.012435</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;function tanh at 0x0000017F5C1350D0&gt;</td>\n",
       "      <td>0.98</td>\n",
       "      <td>17.551077</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function elu at 0x0000017F5C2A0048&gt;</td>\n",
       "      <td>0.98</td>\n",
       "      <td>15.977314</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function tanh at 0x0000017F5C1350D0&gt;</td>\n",
       "      <td>0.96</td>\n",
       "      <td>15.844253</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function relu at 0x0000017F5C2AF598&gt;</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16.029119</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden1  hidden2  hidden3  hidden4  hidden5  \\\n",
       "5       20       20       20       20       20   \n",
       "1       20       20       20       20       20   \n",
       "3       20       20       20       20       20   \n",
       "4       10       10       10       10       10   \n",
       "2       10       10       10       10       10   \n",
       "0       10       10       10       10       10   \n",
       "\n",
       "                              activation  Train Accuracy    Runtime  \\\n",
       "5   <function elu at 0x0000017F5C2A0048>            0.98  19.796811   \n",
       "1  <function relu at 0x0000017F5C2AF598>            0.96  18.012435   \n",
       "3  <function tanh at 0x0000017F5C1350D0>            0.98  17.551077   \n",
       "4   <function elu at 0x0000017F5C2A0048>            0.98  15.977314   \n",
       "2  <function tanh at 0x0000017F5C1350D0>            0.96  15.844253   \n",
       "0  <function relu at 0x0000017F5C2AF598>            0.92  16.029119   \n",
       "\n",
       "   Test Accuracy  layers  \n",
       "5         0.9543       5  \n",
       "1         0.9534       5  \n",
       "3         0.9472       5  \n",
       "4         0.9386       5  \n",
       "2         0.9302       5  \n",
       "0         0.9202       5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordered based on accuracy and runtime\n",
    "result_df_5.sort_values(['Test Accuracy', 'Runtime'], ascending=[0, 1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
