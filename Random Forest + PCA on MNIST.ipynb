{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will be analyzing the MNIST data set, fitting a Random Forest on complete 784 variables, doing PCA on the dataset to find the Principal Components and then fitting another Random Forest using those Principal Components. Once this is complete, the two approaches will be compared in terms of time taken and test performances. Finally, I will be identifying the design flaw in this experiment and re-running it in the regular train and test regimen.\n",
    "\n",
    "I would suggest the Management to use PCA + ML Model for Image Analysis because it has more Precision and Recall than pure ML. Pure ML model might run faster but I think for an Image Classification task Precision and Recall matter and we only want to classify according to Principal components that have a strong presence in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas and test and train datasets\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Setting the seed value for reproducible results\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MNIST\n",
    "\n",
    "import scipy.io\n",
    "mnist = scipy.io.loadmat('mnist-original.mat')\n",
    "X, y = mnist['data'].T.astype(int), mnist['label'].T.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and Test sets\n",
    "\n",
    "y = np.ravel(y,order='C').astype(int)\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Total Time: 5.65 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Scaling data with Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Fitting a Random Forest Classifier\n",
    "# Measuring data\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "rf = RandomForestRegressor(max_features = 'sqrt', bootstrap = True,\n",
    "                           random_state=RANDOM_SEED,\n",
    "                           n_estimators=10)\n",
    "\n",
    "pipeline = make_pipeline(scaler, rf)\n",
    "\n",
    "pipeline.fit(X_train.astype(float), y_train)\n",
    "\n",
    "print(\"--- Total Time: %s seconds ---\" % round((time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = pipeline.predict(X_test.astype(float)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 8, 8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.624\n",
      "Recall Score: 0.582\n",
      "F1 Score: 0.577\n"
     ]
    }
   ],
   "source": [
    "# Importing Precision, Recall and F1 scores\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Precision Score: {:.3f}\".format(precision_score(y_test,\n",
    "                                                       y_test_predict,\n",
    "                                                       average='macro')))\n",
    "\n",
    "print(\"Recall Score: {:.3f}\".format(recall_score(y_test,\n",
    "                                                 y_test_predict,\n",
    "                                                 average='macro')))\n",
    "\n",
    "print(\"F1 Score: {:.3f}\".format(f1_score(y_test,\n",
    "                                         y_test_predict,\n",
    "                                         average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precision and Recall both are above 0.5 for this model and the F1 score is 0.577. This indicates that the model is performing more than average on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "\n",
      "--- Total Time: 12.74 seconds ---\n",
      "\n",
      "Number of Principal components: 154\n"
     ]
    }
   ],
   "source": [
    "# Importing PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Keeping variance 95%\n",
    "\n",
    "pca = PCA(n_components = 0.95)\n",
    "\n",
    "print(pca)\n",
    "\n",
    "# Start Time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fitting the entire dataset\n",
    "\n",
    "X2D = pca.fit_transform(X.astype(float))\n",
    "\n",
    "# End Time\n",
    "\n",
    "print(\"\\n--- Total Time: %s seconds ---\" % round((time.time() - start_time),2))\n",
    "\n",
    "print(\"\\nNumber of Principal components: %s\" % pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier using identified Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Test Train datasets using reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 154)\n"
     ]
    }
   ],
   "source": [
    "print(X2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and Test sets\n",
    "\n",
    "X2D_train = X2D[:60000]\n",
    "\n",
    "X2D_test = X2D[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Total Time: 124.81 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Fitting a Random Forest with 154 components\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf2 = RandomForestRegressor(max_features = 154,\n",
    "                           random_state=RANDOM_SEED,\n",
    "                           n_estimators=10,\n",
    "                           bootstrap = True)\n",
    "\n",
    "pipeline2 = make_pipeline(scaler, rf2)\n",
    "\n",
    "pipeline2.fit(X2D_train.astype(float), y_train)\n",
    "\n",
    "print(\"--- Total Time: %s seconds ---\" % round((time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict2 = pipeline2.predict(X2D_test.astype(float)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.648\n",
      "Recall Score: 0.603\n",
      "F1 Score: 0.600\n"
     ]
    }
   ],
   "source": [
    "# Importing Precision, Recall and F1 scores\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Precision Score: {:.3f}\".format(precision_score(y_test,\n",
    "                                                       y_test_predict2,\n",
    "                                                       average='macro')))\n",
    "\n",
    "print(\"Recall Score: {:.3f}\".format(recall_score(y_test,\n",
    "                                                 y_test_predict2,\n",
    "                                                 average='macro')))\n",
    "\n",
    "print(\"F1 Score: {:.3f}\".format(f1_score(y_test,\n",
    "                                         y_test_predict2,\n",
    "                                         average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precision and Recall both are above 0.6 for this model and the F1 score is 0.600. This indicates that the model is performing more than average over the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Performances between Model 1 (Random Forest with all components) and Model 2 (Random Forest with PCA)\n",
    "\n",
    "F1 Score of Model 2 is 0.600 which is better than Model 1 0.577, and the Precision and Recall scores are also better for Model 2. Therefore, Model 2 is performing better than Model 1.\n",
    "\n",
    "Model 1 took 5.65 seconds whereas Model 2 took (12.74 + 124.81) = 137.55 seconds, which is roughly 24 times more than Model 1. Therefore, Model 2 is more time consuming than Model 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of Design Flaw and Rerun of the Experiment again\n",
    "\n",
    "The Design Flaw with the above experiment is that the PCA analysis was done on the full dataset instead of the Train set whereas the Random Forest Classifier was trained on the Train set. Ideally, the PCA analysis should be done on Train set and then the Test set should be transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Total Time: 11.03 seconds ---\n",
      "\n",
      "Number of Principal components: 154\n"
     ]
    }
   ],
   "source": [
    "# Start Time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fitting the Train & Test dataset\n",
    "\n",
    "X2D_train = pca.fit_transform(X_train.astype(float))\n",
    "\n",
    "X2D_test = pca.transform(X_test.astype(float))\n",
    "\n",
    "# End Time\n",
    "\n",
    "print(\"\\n--- Total Time: %s seconds ---\" % round((time.time() - start_time),2))\n",
    "\n",
    "print(\"\\nNumber of Principal components: %s\" % pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Total Time: 122.37 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Fitting a Random Forest with 154 components\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf3 = RandomForestRegressor(max_features = 154,\n",
    "                           random_state=RANDOM_SEED,\n",
    "                           n_estimators=10,\n",
    "                           bootstrap = True)\n",
    "\n",
    "pipeline2 = make_pipeline(scaler, rf3)\n",
    "\n",
    "pipeline2.fit(X2D_train.astype(float), y_train)\n",
    "\n",
    "print(\"--- Total Time: %s seconds ---\" % round((time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict3 = pipeline2.predict(X2D_test.astype(float)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.654\n",
      "Recall Score: 0.611\n",
      "F1 Score: 0.609\n"
     ]
    }
   ],
   "source": [
    "# Importing Precision, Recall and F1 scores\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Precision Score: {:.3f}\".format(precision_score(y_test,\n",
    "                                                       y_test_predict3,\n",
    "                                                       average='macro')))\n",
    "\n",
    "print(\"Recall Score: {:.3f}\".format(recall_score(y_test,\n",
    "                                                 y_test_predict3,\n",
    "                                                 average='macro')))\n",
    "\n",
    "print(\"F1 Score: {:.3f}\".format(f1_score(y_test,\n",
    "                                         y_test_predict3,\n",
    "                                         average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precision and Recall both are above 0.6 for this model and the F1 score is 0.609 which is slightly better than the two Models in previous experiment. The time taken for this model is also slightly lesser than Model 2 - (11.03 + 122.37) = 133.4 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Management Problem\n",
    "\n",
    "Based on the F1 Score, Precision and Recall performance measures, I would recommend using PCA before ML methods even though the time required to do PCA + ML is more than doing just ML. This is because PCA has better performance for image compression and for our analysis we used a very small number of estimators in Random Forest. Increasing the number of estimators (Decision Trees) in Random Forest might increase the time taken and it is possible that the pure ML Model might take more time than PCA + ML Model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
